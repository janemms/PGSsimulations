---
title: "PGS simulations"
output: html_document
date: "2025-06-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Sampling PGS relative rankings

```{r}
source("PGSvariance.R")
N = 5000
M = 1000
n = 10000
h2 = 0.7
n.samples = 10000
pgs.rankings = PGS.sample.rankings(N, M, n, h2, n.samples, S = -1, 0.9)
```

```{r}
rank.mat = pgs.rankings$pgs.rankings
#rank.mat
#rowMeans(rank.mat)
over.t = pgs.rankings$prop.over.t
over.t[order(over.t, decreasing = TRUE)]
```

(Largest "probabilities" of exceeding the threshold t are:)
(- xxxxxx with h2 = 0.5, N = 100 000, M = 1000, n = 10 000, t = 0.9 and n.samples = 1000.)
(- xxxxxx with h2 = 0.6, N = 100 000, M = 1000, n = 10 000, t = 0.9 and n.samples = 1000.)

### Range of rankings and mean/median rankings

- for each N
  - for each h2
    - for each individual
      -> n.stats
n.stats x N x len(h2) x len(Ns)
```{r}
# pgs.rankings = PGS.sample.rankings(N, M, n, h2, n.samples, S = -1, t = 0.9)

source("PGSvariance.R")
M = 1000 # of SNPs
h2s = c(0.1, 0.25, 0.5, 0.8) # heritabilities
Ns = c(1000, 10000, 100000, 250000, 500000) # of individuals in GWAS training data
n.samples = 10000 #
t = 0.9 # 
n = 10000 # of indivuduals whose PGSs are computed
n.stats = 5 # of statistics to be collected for each individual
len.h2 = length(h2s) # of different heritabilities

# length(Ns) matrices of shape Ns[i] x (n.stats x len(h2s))
#stats.list = lapply(Ns, function(x){matrix(nrow = x, ncol = n.stats*len.h2)}) # list of matrices for different Ns

ranking.stats = matrix(nrow = n, ncol = length(h2s) * n.stats * length(Ns)) 

for (i in 1:length(Ns)){
  for (j in 1:length(h2s)){
    rankings = PGS.sample.rankings(Ns[i], M, n, h2s[j], n.samples, S = -1, t)$pgs.rankings
    # output is a (n x n.samples) matrix of rankings of n.samples PGS estimates for n individuals
    mean = rowMeans(rankings) # mean PGS for each individual
    median = apply(rankings, 1, median) # median PGS for each individual
    min.ranking = apply(rankings, 1, min) # minimums of individuals' rankings
    max.ranking = apply(rankings, 1, max) # maximums of individuals' rankings
    range = max.ranking - min.ranking # range of rankings of an individual
    #sanity.check = colMeans(rankings)
    print(dim(rankings))
    print(dim(cbind(mean, median, min.ranking, max.ranking, range)))
    print(length(mean))
    print(Ns[i])
    print(n.stats)
    print(((j-1)*n.stats+1):(j*n.stats))
    col.start = ((i - 1) * len.h2 + (j - 1)) * n.stats + 1
    col.end = col.start + n.stats - 1

    #stats.list[[i]][, ((j-1)*n.stats+1):(j*n.stats)] = c(mean, median, min.ranking, max.ranking, range) 
    ranking.stats[, col.start:col.end] = c(mean, median, min.ranking, max.ranking, range)
    #
  }
  
}


```

```{r}
stat.names <- c("mean", "median", "min", "max", "range")
col.names <- c()

for (i in seq_along(Ns)) {
  for (j in seq_along(h2s)) {
    for (stat in stat.names) {
      col.names <- c(col.names, paste0("N", Ns[i], ".h2.", h2s[j], ".", stat))
    }
  }
}
colnames(ranking.stats) = col.names # set column names

head(ranking.stats)

```

```{r}
# mean range of rankings for each N and h2
range.cols = seq(from = n.stats, to = ncol(ranking.stats), by = n.stats)
range.means = colMeans(ranking.stats[,range.cols])

range.mat = matrix(range.means, nrow = length(Ns), ncol = length(h2s), byrow = FALSE) # format

rownames(range.mat) <- paste0("N = ", Ns)
colnames(range.mat) <- paste0("h2 = ", h2s)

range.mat
```

### Proportion of individual PGS estimates over t

```{r}
source("PGSvariance.R")
M = 1000 # of SNPs
h2s = c(0.1, 0.25, 0.5, 0.8) # heritabilities
Ns = c(1000, 10000, 100000, 250000, 500000) # of individuals
n.samples = 10000 #
t = 0.9 # 
n = 10000 

proportions = matrix(nrow = n, ncol = length(h2s)*length(Ns)) # proportion of PGS estimates over t for each individual, for each N and h2

for (j in 1:length(h2s)){
  for (i in 1:length(Ns)){
    proportions[,((i-1)*length(h2s)+j)] = PGS.sample.rankings(Ns[i], M, n, h2s[j], n.samples, S = -1, t)$prop.over.t
  }
}
```

```{r}
col.names <- c()

for (i in seq_along(Ns)) {
  for (j in seq_along(h2s)) {
      col.names <- c(col.names, paste0("N", Ns[i], ".h2.", h2s[j]))
  }
}
colnames(proportions) = col.names # set column names

```

```{r}
apply(proportions, 2, max)
```

```{r}
library(reshape2)
library(ggplot2)

n.individuals = nrow(proportions) # dimensions (n)

N.rep = rep(Ns, each = length(h2s)) # metadata for the columns
h2.rep = rep(h2s, times = length(Ns))

prop.df = as.data.frame(proportions) # convert to data frame
colnames(prop.df) = paste0("N", N.rep, "_h2_", h2.rep)

prop.long = melt(prop.df, variable.name = "Condition", value.name = "Proportion") # reshape to long format

prop.long$N <- as.numeric(sub("N(\\d+)_h2_.*", "\\1", prop.long$Condition)) # extract N and h2 from column names with regex
prop.long$h2 <- as.numeric(sub(".*_h2_(.*)", "\\1", prop.long$Condition))

```

```{r}
ggplot(prop.long, aes(x = factor(N), y = Proportion, color = factor(h2))) +
  stat_summary(fun = mean, geom = "point", position = position_dodge(width = 0.5)) +
  stat_summary(fun = mean, geom = "line", aes(group = h2), position = position_dodge(width = 0.5)) +
  labs(x = "Sample size (N)", y = "Proportion over t", color = "hÂ²") +
  theme_minimal()

```


## Order-correlation of sampled PGS estimates

A function for computing the rank correlations
```{r} 
compute.rank.correlations <- function(pgs.ranks, n.pairs = 1000, seed = 42) {
  set.seed(seed)
  #pgs.ranks = t(pgs.ranks) # n.sample rankings for the n indviduals, t(n x n.samples) matrix = (n.samples x n) matrix
  n.samples = ncol(pgs.ranks) # of samples (ranks) for each individual
  
  all.pairs = combn(n.samples, 2) # all unique combinations of indices of samples (2 x jotain) matrix
  nof.pairs = ncol(all.pairs) # of unique pairs
  sample.ind = sample(nof.pairs, min(n.pairs, length(all.pairs))) # samples the n.pairs pairs from the possible pairs nof.pairs
  
  sampled.pairs = as.matrix(all.pairs[,sample.ind, drop = FALSE]) # n.pairs based on sample.ind (2 x n.pairs) matrix
  
  corrs = apply(sampled.pairs, 2, function(pair){cor(pgs.ranks[, pair[1]], pgs.ranks[, pair[2]], method = "spearman")}) # compute Spearman correlations for each pairs
  return(corrs)
}

```

```{r}
source("PGSvariance.R")
# n.samples ranks from each individual
M = 1000 # of SNPs
h2s = c(0.1, 0.25, 0.5, 0.8) # heritabilities
Ns = c(1000, 10000, 100000, 250000, 500000) # of individuals
n.samples = 10000 #
t = 0.9 # 
n = 10000 

rank.correlations = matrix(nrow = n, ncol = length(h2s)*length(Ns)) # proportion of PGS estimates over t for each individual, for each N and h2

for (j in 1:length(h2s)){
  for (i in 1:length(Ns)){
    ranks = PGS.sample.rankings(Ns[i], M, n, h2s[j], n.samples, S = -1, t)$pgs.rankings
    rank.correlations[,((i-1)*length(h2s)+j)] = compute.rank.correlations(ranks)
  }
}
```

```{r}
col.names <- c()

for (i in seq_along(Ns)) {
  for (j in seq_along(h2s)) {
      col.names <- c(col.names, paste0("N", Ns[i], ".h2.", h2s[j]))
  }
}
colnames(rank.correlations) = col.names # set column names

colMeans(rank.correlations)


```

```{r}
# violin plot rank correlations
# divide data points into bins (10) for each h2 and N
# plot aggregated points as mean correlations of the bins for each N and h2

# divide into bins 
n.bins = 10

# for each column, split data into bins and compute mean for each bin



```




2 samples for each individual
-> correlation, plot all individual correlations as a violin plot,
    with different h2 and N


