---
title: "generateGeno"
output: html_document
date: "2025-06-12"
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
```

# Uncertainty in PGS estimates

Generate allele 1 frequencies from a uniform distribution on (0,1).
We assume allele frequencies to follow HWE.

```{r}
M = 10000 # of SNPs, test with different ones
N = 1000 # of individuals, fixed at first
ps = runif(M, 0, 1) #  allele 1 frequencies for M SNPs

h2 = 0.5 # assumed heritability, TODO: vary heritability 
```

#### Simplified effect sizes

At first, the true effect sizes are assumed to come from normal distribution $\beta \sim N(0, 1)$.
TODO: correct distribution parameters

Simulate true effect sizes and effect size estimates with noise proportional to sample size.

```{r}
betas.s = rnorm(M, 0, 1) # draw true effect sizes from standard normal distribution
beta.s.est = betas.s + 1/N * rnorm(M, 0, 1) # add noise proportional to sample size
```

#### Effect sizes taking into account negative selection

We account for negative selection by assuming that the magnitude of effects $\beta^2$ is proportional to $(2p(1-p))^S$, where $S=-1$.
This is done by drawing effect estimates from a multinomial normal distribution with mean 0 and variance of $(2p(1-p))^S$.
Here we assume each SNP contributes equally to the total variance, with the variances summing up to $h^2$.
Draw true effects from a normal distribution, which sd is proportional to heritability.
The effects are estimated as in GWAS, by adding a random error term to the true estimate: $\hat{\beta} = \beta + \epsilon$, where $\epsilon \sim N(0,1/N)$.

```{r}
S = -1 # relative contributions of common vs rare variants
var.neg = h2/((2*ps*(1-ps))^S*M) # variance proportional to negative selection coefficient, scaled to match heritability h2 and M SNPs
betas.neg = rnorm(M, mean = 0, sd = sqrt(var.neg)) # draw betas with variance var.neg

beta.neg.est = betas.neg + 1/N * rnorm(M, 0, 1) # add noise proportional to sample size
summary(beta.neg.est)
```

**TODO**: plot 1/N against PGS variance

Generate genotypes for N = {1000, 10000, 100000, 500000} individuals at 1000 loci assuming allele frequencies follow HWE.

```{r}
genotypes = matrix(nrow = N, ncol = M)
for (i in 1:M) {
  genotypes[, i] = rbinom(N, size = 2, prob = ps[i])
}
# TODO: vectorize for performance

```

#### Individual PGS estimates

For each individual, we compute the PGS estimate as a weighted sum of their genotypes and corresponding effect estimates.
**Note!** Each individual has their own genotypes, but the same effect estimates.
We also compute the uncertainty in the effect estimate as a variance of the linear combination, assuming the random errors are independent.

```{r}
pgs = genotypes %*% beta.neg.est # compute PGS accounting for negative selection
pgs.var = 1/N * rowSums(genotypes^2) # variance in individual PGS estimates due to noise in the effect size estimates
```

#### Individual PGS estimates by sampling

TODO: how to get the variance in the beta estimates, which formula to use for PGS variance TODO: Try also: generate 1000 samples of the beta estimates, and for each sample compute the PGS for each individual, and compute the variance of these estimates.

Then, adjust the simulation by assuming negative selection: the magnitude of effects $\beta^2$ is proportional to $(2p(1-p))^S$, where $S=-1$.
(maybe sample betas from a standard normal distribution and the scale with the formula)

 
```{r}
source("generategeno.R")
pgs.unc = PGS.uncertainty(100000, 5000, 0.5, -1)
summary(pgs.unc$pgs)
summary(pgs.unc$variance)
```

```{r}
source("generategeno.R")
pgs.sample.unc = PGS.sample.uncertainty(1000, 10000, 0.5, -1, 1000)
summary(pgs.sample.unc$pgs)
summary(pgs.sample.unc$variance)
#ordered.estimates(pgs.sample.unc$pgs, pgs.sample.unc$variance, 0.99, 0.95)

```
#### Sampled PGS variance with different N

```{r}
source("generategeno.R")
ns = c(100, 1000, 10000, 50000)
M = 10000 # of SNPs
h2 = 0.5 # heritability
S = -1
nsamp = 1000
pgs.vars = vector("list", length(ns))

for (i in 1:length(ns)){
  pgs.vars[[i]] = PGS.uncertainty(ns[i], M, h2, S)$variance
}
```


```{r}

all.pgs.var = unlist(pgs.vars)

# a matching vector of sample sizes for each variance value
sample.size = rep(ns, times = ns)
# a data frame for plotting
df = data.frame(N = sample.size, Variance = all.pgs.var)

ggplot(df, aes(x = N, y = Variance)) +
  geom_point(alpha = 0.2, color = "steelblue") +
  scale_x_log10() +
  scale_y_log10() +
  labs(title = "PGS Variance Across Sample Sizes",
       x = "Sample Size (log10 scale)",
       y = "Variance of PGS") 
```

#### Ordered PGS estimates with variance
```{r}
source("generategeno.R")
top.pgs = ordered.estimates(pgs.unc$pgs, pgs.unc$variance, 0.90, 0.95) # top 1 % PGS values with confidence level 0.95
top.pgs$prop.certain.above
top.pgs$prop.certain.below

```


#### 
```{r}
rho = 0.95 
S = -1
```

M = 1000 and N = 1000, 10 000, 100 000, 250 000, 500 000
- h2 = 0.1, 0.25, 0.5, 0.8

```{r}
M = 1000
Ns = c(1000, 10000, 100000, 250000, 500000) # of individuals
t = 0.9 # 
# (PGSs and) variances from PGS.uncertainty
  # Ns[i] # of variances for each iteration
    # collect variances
  # proportion of PGSs certainly over t from ordered.estimates
# plot variances of individual PGSs as a function of # of individuals, add prop.confident as label for each Ns[i]

pgs.s1 = vector("list", length(Ns))
pgs.vars.s1 = vector("list", length(Ns))

for (i in 1:length(Ns)){
  pgs.unc.s1 = PGS.uncertainty(Ns[i], M, h2, S)
  pgs.s1[[i]] = pgs.unc.s1$pgs # PGSs for N = Ns[i]
  pgs.vars.s1[[i]] = pgs.unc.s1$variance # variances of PGSs for N = Ns[i]
}
all.s1 = unlist(pgs.s1) # all pgs concatenated
all.var.s1 = unlist(pgs.vars.s1) # all pgs variances concatenated

sample.size = rep(Ns, times = Ns) # matching vector of sample sizes for each PGS and variance value

df.var = data.frame(N = sample.size, Variance = all.var.s1) # data frame for plotting

## proportion of PGS estimates certain above t 
#ordered.s1 = ordered.estimates()

```





M = 10 000 and N = 1000, 10 000, 50 000
- h2 = 0.1, 0.25, 0.5, 0.8

N = 50 000 and M = 500, 1000, 5 000, 10 000
- h2 = 0.1, 0.25, 0.5, 0.8

N = 100 000, M = 5000 and t = 0.9, 0.95, 0.99





